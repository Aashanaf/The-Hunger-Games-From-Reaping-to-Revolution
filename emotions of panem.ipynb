{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Insatallations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "804b2b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\the hunger games saga\\panem\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in d:\\the hunger games saga\\panem\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in d:\\the hunger games saga\\panem\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in d:\\the hunger games saga\\panem\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in d:\\the hunger games saga\\panem\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\the hunger games saga\\panem\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\the hunger games saga\\panem\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\the hunger games saga\\panem\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\the hunger games saga\\panem\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\the hunger games saga\\panem\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\the hunger games saga\\panem\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in d:\\the hunger games saga\\panem\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\the hunger games saga\\panem\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: colorama in d:\\the hunger games saga\\panem\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\the hunger games saga\\panem\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\the hunger games saga\\panem\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\the hunger games saga\\panem\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\the hunger games saga\\panem\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\the hunger games saga\\panem\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\the hunger games saga\\panem\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to d:\\The Hunger Games\n",
      "[nltk_data]     Saga\\Panem\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required Libraries\n",
    "!pip install transformers torch pandas nltk tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f70cf7",
   "metadata": {},
   "source": [
    "Emotion Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "918475b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the required Characters \n",
    "CHARACTER_NAMES = [\n",
    "    \"Katniss_Everdeen\", \"Peeta_Mellark\", \"Gale_Hawthorne\", \"Effie_Trinket\",\n",
    "    \"Finnick_Odair\", \"Johanna_Mason\", \"President_Coriolanus_Snow\", \"Alma_Coin\"\n",
    "]\n",
    "\n",
    "# Exclude emotions: positive, negative, neutral\n",
    "def load_nrc_lexicon(filepath=\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"):\n",
    "    nrc = defaultdict(set)\n",
    "    exclude_emotions = {\"positive\", \"negative\", \"neutral\"}  \n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            parts = re.split(r'\\s+', line)  # handles tabs or spaces\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            word, emotion, association = parts\n",
    "            if association == '1' and emotion not in exclude_emotions:  # Exclude 'positive', 'negative', 'neutral'\n",
    "                nrc[word].add(emotion)\n",
    "    return nrc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "faf3133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count emotions using lexicon\n",
    "def count_emotions(text_list, character_name, lexicon):\n",
    "    emotion_counter = Counter()\n",
    "    all_words = []\n",
    "\n",
    "    # Tokenize and filter words\n",
    "    for text in text_list:\n",
    "        words = word_tokenize(text.lower())\n",
    "        words = [w for w in words if w.isalpha()]\n",
    "        all_words.extend(words)\n",
    "\n",
    "    for word in all_words:\n",
    "        if word in lexicon:\n",
    "            for emotion in lexicon[word]:\n",
    "                emotion_counter[emotion] += 1\n",
    "\n",
    "    return emotion_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8360f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 3 emotions\n",
    "def display_top_emotions(emotion_counter, character_name):\n",
    "    top_emotions = emotion_counter.most_common(3)\n",
    "    emotion_line = f\"{character_name.replace('_', ' ')}: \"\n",
    "    emotion_line += \", \".join([emotion for emotion, _ in top_emotions])\n",
    "    print(emotion_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8686b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting data in a list for later tabular display\n",
    "emotion_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d51c1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each character to count emotions\n",
    "nrc_lexicon = load_nrc_lexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b6bd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for each character\n",
    "for character_name in CHARACTER_NAMES:\n",
    "    try:\n",
    "        df = pd.read_csv(f\"data/raw/{character_name}.csv\")\n",
    "        paragraphs = df['paragraph'].dropna().tolist()\n",
    "        emotion_counts = count_emotions(paragraphs, character_name, nrc_lexicon)\n",
    "\n",
    "        # Get the top 3 emotions\n",
    "        top_emotions = emotion_counts.most_common(3)\n",
    "\n",
    "        # Prepare data for table\n",
    "        character_data = {\n",
    "            \"Character\": character_name.replace(\"_\", \" \"),\n",
    "            \"Top Emotion 1\": top_emotions[0][0] if len(top_emotions) > 0 else None,\n",
    "            \"Score 1\": top_emotions[0][1] if len(top_emotions) > 0 else None,\n",
    "            \"Top Emotion 2\": top_emotions[1][0] if len(top_emotions) > 1 else None,\n",
    "            \"Score 2\": top_emotions[1][1] if len(top_emotions) > 1 else None,\n",
    "            \"Top Emotion 3\": top_emotions[2][0] if len(top_emotions) > 2 else None,\n",
    "            \"Score 3\": top_emotions[2][1] if len(top_emotions) > 2 else None,\n",
    "        }\n",
    "\n",
    "        emotion_summary.append(character_data)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found for {character_name}. Skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {character_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f06a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ad7ff\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ad7ff_level0_col0\" class=\"col_heading level0 col0\" >Character</th>\n",
       "      <th id=\"T_ad7ff_level0_col1\" class=\"col_heading level0 col1\" >Top Emotion 1</th>\n",
       "      <th id=\"T_ad7ff_level0_col2\" class=\"col_heading level0 col2\" >Score 1</th>\n",
       "      <th id=\"T_ad7ff_level0_col3\" class=\"col_heading level0 col3\" >Top Emotion 2</th>\n",
       "      <th id=\"T_ad7ff_level0_col4\" class=\"col_heading level0 col4\" >Score 2</th>\n",
       "      <th id=\"T_ad7ff_level0_col5\" class=\"col_heading level0 col5\" >Top Emotion 3</th>\n",
       "      <th id=\"T_ad7ff_level0_col6\" class=\"col_heading level0 col6\" >Score 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row0_col0\" class=\"data row0 col0\" >Katniss Everdeen</td>\n",
       "      <td id=\"T_ad7ff_row0_col1\" class=\"data row0 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row0_col2\" class=\"data row0 col2\" >363</td>\n",
       "      <td id=\"T_ad7ff_row0_col3\" class=\"data row0 col3\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row0_col4\" class=\"data row0 col4\" >336</td>\n",
       "      <td id=\"T_ad7ff_row0_col5\" class=\"data row0 col5\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row0_col6\" class=\"data row0 col6\" >293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row1_col0\" class=\"data row1 col0\" >Peeta Mellark</td>\n",
       "      <td id=\"T_ad7ff_row1_col1\" class=\"data row1 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row1_col2\" class=\"data row1 col2\" >228</td>\n",
       "      <td id=\"T_ad7ff_row1_col3\" class=\"data row1 col3\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row1_col4\" class=\"data row1 col4\" >222</td>\n",
       "      <td id=\"T_ad7ff_row1_col5\" class=\"data row1 col5\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row1_col6\" class=\"data row1 col6\" >206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row2_col0\" class=\"data row2 col0\" >Gale Hawthorne</td>\n",
       "      <td id=\"T_ad7ff_row2_col1\" class=\"data row2 col1\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row2_col2\" class=\"data row2 col2\" >174</td>\n",
       "      <td id=\"T_ad7ff_row2_col3\" class=\"data row2 col3\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row2_col4\" class=\"data row2 col4\" >171</td>\n",
       "      <td id=\"T_ad7ff_row2_col5\" class=\"data row2 col5\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row2_col6\" class=\"data row2 col6\" >134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row3_col0\" class=\"data row3 col0\" >Effie Trinket</td>\n",
       "      <td id=\"T_ad7ff_row3_col1\" class=\"data row3 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row3_col2\" class=\"data row3 col2\" >99</td>\n",
       "      <td id=\"T_ad7ff_row3_col3\" class=\"data row3 col3\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row3_col4\" class=\"data row3 col4\" >78</td>\n",
       "      <td id=\"T_ad7ff_row3_col5\" class=\"data row3 col5\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row3_col6\" class=\"data row3 col6\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row4_col0\" class=\"data row4 col0\" >Finnick Odair</td>\n",
       "      <td id=\"T_ad7ff_row4_col1\" class=\"data row4 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row4_col2\" class=\"data row4 col2\" >138</td>\n",
       "      <td id=\"T_ad7ff_row4_col3\" class=\"data row4 col3\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row4_col4\" class=\"data row4 col4\" >125</td>\n",
       "      <td id=\"T_ad7ff_row4_col5\" class=\"data row4 col5\" >joy</td>\n",
       "      <td id=\"T_ad7ff_row4_col6\" class=\"data row4 col6\" >110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row5_col0\" class=\"data row5 col0\" >Johanna Mason</td>\n",
       "      <td id=\"T_ad7ff_row5_col1\" class=\"data row5 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row5_col2\" class=\"data row5 col2\" >99</td>\n",
       "      <td id=\"T_ad7ff_row5_col3\" class=\"data row5 col3\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row5_col4\" class=\"data row5 col4\" >93</td>\n",
       "      <td id=\"T_ad7ff_row5_col5\" class=\"data row5 col5\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row5_col6\" class=\"data row5 col6\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row6_col0\" class=\"data row6 col0\" >President Coriolanus Snow</td>\n",
       "      <td id=\"T_ad7ff_row6_col1\" class=\"data row6 col1\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row6_col2\" class=\"data row6 col2\" >301</td>\n",
       "      <td id=\"T_ad7ff_row6_col3\" class=\"data row6 col3\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row6_col4\" class=\"data row6 col4\" >292</td>\n",
       "      <td id=\"T_ad7ff_row6_col5\" class=\"data row6 col5\" >sadness</td>\n",
       "      <td id=\"T_ad7ff_row6_col6\" class=\"data row6 col6\" >269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ad7ff_row7_col0\" class=\"data row7 col0\" >Alma Coin</td>\n",
       "      <td id=\"T_ad7ff_row7_col1\" class=\"data row7 col1\" >trust</td>\n",
       "      <td id=\"T_ad7ff_row7_col2\" class=\"data row7 col2\" >75</td>\n",
       "      <td id=\"T_ad7ff_row7_col3\" class=\"data row7 col3\" >fear</td>\n",
       "      <td id=\"T_ad7ff_row7_col4\" class=\"data row7 col4\" >58</td>\n",
       "      <td id=\"T_ad7ff_row7_col5\" class=\"data row7 col5\" >anticipation</td>\n",
       "      <td id=\"T_ad7ff_row7_col6\" class=\"data row7 col6\" >47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eeffec3390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert summary data into a DataFrame\n",
    "summary_df = pd.DataFrame(emotion_summary)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "display(\n",
    "    summary_df.style\n",
    "    .hide(axis='index')  # Hides the index column\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Panem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
